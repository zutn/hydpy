anntools

This module implements rudimantary artificial neural network tools,
required for some models implemented in the HydPy framework.

A note for developers: some of the implemented features are to be
applied during model simulations are in some other way performance-
critical.  Hence, the actual calculations are defined in the Cython
extension module "annutils".

Module

anntools

 implements the following members:

   ANN Multi-layer feed forward artificial neural network.

   ann() Return a new stand alone ANN object with the given parameter
   values.

   SeasonalANN Handles relationships described by artificial neural
   networks that vary within an anual cycle.


class hydpy.auxs.anntools.ANN

   Bases:

   object

   Multi-layer feed forward artificial neural network.

   The applied activation function is the logistic function:

      f(x) = \frac{1}{1+exp(-x)}

   Class

   ANN

    is intended to be subclassed for the derivation of very complex
   control parameters.  Its original purpose was to allow for defining
   arbitrary continuous relationsships between the water stored in a
   dam and the associated water stage (see model ...).  However, class

   ANN

    can also be applied directly, as shown in the following examples.
   But if you are looking for a flexible stand-alone artifical neural
   network implementation in Python, you will find much more general
   tools easily.

   Firstly, define the most single artificial neural network
   consisting of only one input node, neuron, and output node
   respectively, and pass some arbitrary network parameters:

   >>> from hydpy import ANN, nan
   >>> ann = ANN()
   >>> ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...     weights_input=4.0, weights_output=3.0,
   ...     intercepts_hidden=-16.0, intercepts_output=-1.0)

   The following loop subsequently sets the values 0 to 8 as input
   values, performs the calculateion, and prints out the final output.
   As to be expected, the results show the shape of the logistic
   function:

   >>> from hydpy import round_
   >>> for input_ in range(9):
   ...     ann.inputs[0] = input_
   ...     ann.process_actual_input()
   ...     round_([input_, ann.outputs[0]])
   0, -1.0
   1, -0.999982
   2, -0.998994
   3, -0.946041
   4, 0.5
   5, 1.946041
   6, 1.998994
   7, 1.999982
   8, 2.0

   One can also directly plot the resulting graph:

   >>> ann.plot(0.0, 8.0)

   The following example shows that everything works well for more
   complex single layer networks also (manual tests have been
   performed in a spreadsheet program):

   >>> ann.nmb_inputs = 3
   >>> ann.nmb_neurons = (4,)
   >>> ann.nmb_outputs = 2
   >>> ann.weights_input = [[ 0.2, -0.1, -1.7,  0.6],
   ...                      [ 0.9,  0.2,  0.8,  0.0],
   ...                      [-0.5, -1.0,  2.3, -0.4]]
   >>> ann.weights_output = [[ 0.0,  2.0],
   ...                       [-0.5,  1.0],
   ...                       [ 0.4,  2.4],
   ...                       [ 0.8, -0.9]]
   >>> ann.intercepts_hidden = [ 0.9,  0.0, -0.4, -0.2]
   >>> ann.intercepts_output = [ 1.3, -2.0]
   >>> ann.inputs = [-0.1,  1.3,  1.6]
   >>> ann.process_actual_input()
   >>> round_(ann.outputs)
   1.822222, 1.876983

   The next example shows how to solve the XOR problem with a two
   layer network.  As usual, *1* stands for *True* and *0* stands for
   *False*.

   We define a network with two inputs (*I1* and *I2*), two neurons in
   the first hidden layer (*H11* and *H12*), one neuron in the second
   hidden layer (*H2*), and a single output (*O1*):

   >>> ann.nmb_inputs = 2
   >>> ann.nmb_neurons = (2, 1)
   >>> ann.nmb_outputs = 1

   The value of *O1* shall be identical with the activation of *H2*:

   >>> ann.weights_output = 1.0
   >>> ann.intercepts_output = 0.0

   All intercepts of the neurons of the hidden layer are set to 750,
   so that an input of 500 results in an activation of approximately
   zero and an input of 1000 results in an activation of approximately
   one (note that matrix entries are not required should preferably be
   initialized with *nan* to avoid confusion):

   >>> ann.intercepts_hidden = [[-750.0, -750.0],
   ...                          [-750.0, nan]]

   The weighting factor between the both inputs and *H11* is 1000.
   Hence, one *True* input is sufficient to activate *H1*.  In
   contrast, the weighting factor between the both inputs and *H12* is
   500 only. Hence, two *True* inputs are required to activate *H12*:

   >>> ann.weights_input= [[1000.0, 500.0],
   ...                     [1000.0, 500.0]]

   The weighting factor between *H11* and *H2* is 1000.  Hence, in
   principle, *H11* can activate *H2*.  However, the weighting factor
   between *H12* and *H2* is -1000.  Hence, *H12* is able to prevent
   *H2* from becoming activated even when *H11* is activated:

   >>> ann.weights_hidden= [[[1000.0, nan],
   ...                      [-1000.0, nan]]]

   To recapitulate, *H11* determines if at least one input is *True*,
   *H12* determines if both inputs are *True*, and *H2* determines if
   exactly one input is *True*, which is the solution for the XOR-
   problem:

   >>> ann
   ann(nmb_inputs=2,
       nmb_neurons=(2, 1),
       nmb_outputs=1,
       weights_input=[[1000.0, 500.0],
                      [1000.0, 500.0]],
       weights_hidden=[[[1000.0, nan],
                        [-1000.0, nan]]],
       weights_output=[[1.0]],
       intercepts_hidden=[[-750.0, -750.0],
                          [-750.0, nan]],
       intercepts_output=[0.0])

   The following calculation confirms that the network is properly
   configured:

   >>> for inputs in ((0.0, 0.0),
   ...                (1.0, 0.0),
   ...                (0.0, 1.0),
   ...                (1.0, 1.0)):
   ...    ann.inputs = inputs
   ...    ann.process_actual_input()
   ...    print(inputs[0], inputs[1], ann.outputs[0])
   0.0 0.0 0.0
   1.0 0.0 1.0
   0.0 1.0 1.0
   1.0 1.0 0.0

   To elaborate on the last calculation, the corresponding activations
   of the hidden neurons are shown. As both inputs are *True*, both
   *H12* (upper left value) and *H22* (upper right value) activated,
   but *H2* (lower left value) is not:

   >>> ann.neurons
   array([[ 1.,  1.],
          [ 0.,  0.]])

   The last defined configuration is used in some examples of the
   documentation of the members of class

   ANN

   :

   >>> from hydpy import dummies
   >>> dummies.ann = ann

   Note that Python class

   ANN

    handles a corresponding Cython extension class defined in
   "annutils", which does not protect itself against segmentation
   faults. But class

   ANN

    takes up this task, meaning using its public members should always
   result in readable exceptions instead of program crashes, e.g.:

   >>> ANN().nmb_layers
   Traceback (most recent call last):
   ...
   AttributeNotReady: Attribute `nmb_layers` of object `ann` is not usable so far.

   NDIM = 0

   TYPE = 'annutils.ANN'

   TIME = None

   SPAN = (None, None)

   parameterstep = Period()

   simulationstep = Period()

   connect(subpars)

      Connect the actual

      ANN

       object with the given

      SubParameters

       object.

   name

      Name of the class of the given instance in lower case letters.

      This function is thought to be implemented as a property.
      Otherwise it would violate the principle not to access or
      manipulate private attributes ("_name"):

      >>> from hydpy.core.objecttools import name
      >>> class Test(object):
      ...     name = property(name)
      >>> test1 = Test()
      >>> test1.name
      'test'
      >>> test1._name
      'test'

      The private attribute is added for performance reasons only.
      Note that it is a class attribute:

      >>> test2 = Test()
      >>> test2._name
      'test'

   nmb_inputs

      Number of input nodes.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_inputs
      2

   nmb_outputs

      Number of output nodes.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_outputs
      1

   nmb_layers

      Number of hidden layers.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_layers
      2

   nmb_neurons

      Number of neurons of the hidden layers.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_neurons
      (2, 1)

   weights_input

      Weights between all input nodes and neurons of the first hidden
      layer.

      The input nodes and the neurons are varied on the first axis and
      on the second axis of the 2-dimensional array:

      >>> from hydpy import ANN
      >>> ann = ANN()
      >>> ann(nmb_inputs=2, nmb_neurons=(3,))
      >>> ann.weights_input
      array([[ 0.,  0.,  0.],
             [ 0.,  0.,  0.]])

      It is allowed to set values via slicing:

      >>> ann.weights_input[:, 0] = 1.
      >>> ann.weights_input
      array([[ 1.,  0.,  0.],
             [ 1.,  0.,  0.]])

      If possible, type conversions are performed:

      >>> ann.weights_input = '2'
      >>> ann.weights_input
      array([[ 2.,  2.,  2.],
             [ 2.,  2.,  2.]])

      One can assign whole matrices directly:

      >>> import numpy
      >>> ann.weights_input = numpy.eye(2, 3)
      >>> ann.weights_input
      array([[ 1.,  0.,  0.],
      ...    [ 0.,  1.,  0.]])

      One can also delete the values contained in the array:

      >>> del ann.weights_input
      >>> ann.weights_input
      array([[ 0.,  0.,  0.],
      ...    [ 0.,  0.,  0.]])

      Errors like wrong shapes (or unconvertible inputs) result in
      error messages:

      >>> ann.weights_input = numpy.eye(3)
      Traceback (most recent call last):
      ...
      ValueError: While trying to set the input weights of the artificial neural network `ann` of element `?`, the following error occured: could not broadcast input array from shape (3,3) into shape (2,3)

   shape_weights_input

      Shape of the array containing the input weights.

      >>> from hydpy import dummies
      >>> dummies.ann.shape_weights_input
      (2, 2)

   nmb_weights_input

      Number of input weights.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_weights_input
      4

   weights_output

      Weights between all neurons of the last hidden layer and the
      output nodes.

      The neurons and the output nodes are varied on the first axis
      and on the second axis of the 2-dimensional array:

      >>> from hydpy import ANN
      >>> ann = ANN()
      >>> ann(nmb_outputs=2, nmb_neurons=(3,))
      >>> ann.weights_output
      array([[ 0.,  0.],
             [ 0.,  0.],
             [ 0.,  0.]])

      It is allowed to set values via slicing:

      >>> ann.weights_output[:, 0] = 1.
      >>> ann.weights_output
      array([[ 1.,  0.],
             [ 1.,  0.],
             [ 1.,  0.]])

      If possible, type conversions are performed:

      >>> ann.weights_output = '2'
      >>> ann.weights_output
      array([[ 2.,  2.],
             [ 2.,  2.],
             [ 2.,  2.]])

      One can assign whole matrices directly:

      >>> import numpy
      >>> ann.weights_output = numpy.eye(3, 2)
      >>> ann.weights_output
      array([[ 1.,  0.],
             [ 0.,  1.],
             [ 0.,  0.]])

      One can also delete the values contained in the array:

      >>> del ann.weights_output
      >>> ann.weights_output
      array([[ 0.,  0.],
             [ 0.,  0.],
             [ 0.,  0.]])

      Errors like wrong shapes (or unconvertible inputs) result in
      error messages:

      >>> ann.weights_output = numpy.eye(3)
      Traceback (most recent call last):
      ...
      ValueError: While trying to set the output weights of the artificial neural network `ann` of element `?`, the following error occured: could not broadcast input array from shape (3,3) into shape (3,2)

   shape_weights_output

      Shape of the array containing the output weights.

      >>> from hydpy import dummies
      >>> dummies.ann.shape_weights_output
      (1, 1)

   nmb_weights_output

      Number of output weights.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_weights_output
      1

   weights_hidden

      Weights between between the neurons of the different hidden
      layers.

      The layers are varied on the first axis, the neurons of the
      respective upstream layer on the second axis and the neurons of
      the respective downstream layer on the third axis of a
      3-dimensional array:

      >>> from hydpy import ANN
      >>> ann = ANN()
      >>> ann(nmb_neurons=(3, 2, 3))
      >>> ann.weights_hidden
      array([[[  0.,   0.,  nan],
              [  0.,   0.,  nan],
              [  0.,   0.,  nan]],
      <BLANKLINE>
             [[  0.,   0.,   0.],
              [  0.,   0.,   0.],
              [ nan,  nan,  nan]]])

      It is allowed to set values via slicing:

      >>> ann.weights_hidden[1, :, 0] = 1.
      >>> ann.weights_hidden
      array([[[  0.,   0.,  nan],
              [  0.,   0.,  nan],
              [  0.,   0.,  nan]],
      <BLANKLINE>
             [[  1.,   0.,   0.],
              [  1.,   0.,   0.],
              [  1.,  nan,  nan]]])

      If possible, type conversions are performed:

      >>> ann.weights_hidden = '2'
      >>> ann.weights_hidden
      array([[[ 2.,  2.,  2.],
              [ 2.,  2.,  2.],
              [ 2.,  2.,  2.]],
      <BLANKLINE>
             [[ 2.,  2.,  2.],
              [ 2.,  2.,  2.],
              [ 2.,  2.,  2.]]])

      One can assign whole matrices directly:

      >>> import numpy
      >>> ann.weights_hidden = numpy.eye(3)
      >>> ann.weights_hidden
      array([[[ 1.,  0.,  0.],
              [ 0.,  1.,  0.],
              [ 0.,  0.,  1.]],
      <BLANKLINE>
             [[ 1.,  0.,  0.],
              [ 0.,  1.,  0.],
              [ 0.,  0.,  1.]]])

      One can also delete the values contained in the array:

      >>> del ann.weights_hidden
      >>> ann.weights_hidden
      array([[[  0.,   0.,  nan],
              [  0.,   0.,  nan],
              [  0.,   0.,  nan]],
      <BLANKLINE>
             [[  0.,   0.,   0.],
              [  0.,   0.,   0.],
              [ nan,  nan,  nan]]])

      Errors like wrong shapes (or unconvertible inputs) result in
      error messages:

      >>> ann.weights_hidden = numpy.eye(3, 2)
      Traceback (most recent call last):
      ...
      ValueError: While trying to set the hidden weights of the artificial neural network `ann` of element `?`, the following error occured: could not broadcast input array from shape (3,2) into shape (2,3,3)

   shape_weights_hidden

      Shape of the array containing the activation of the hidden
      neurons.

      >>> from hydpy import dummies
      >>> dummies.ann.shape_weights_hidden
      (1, 2, 2)

   nmb_weights_hidden

      Number of hidden weights.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_weights_hidden
      2

   intercepts_hidden

      Intercepts of all neurons of the hidden layers.

      All intercepts are handled in a 1-dimensional array:

      >>> from hydpy import ANN
      >>> ann = ANN()
      >>> ann(nmb_neurons=(3, 2))
      >>> ann.intercepts_hidden
      array([[  0.,   0.,   0.],
             [  0.,   0.,  nan]])

      It is allowed to set values via slicing:

      >>> ann.intercepts_hidden[0, :] = 1.
      >>> ann.intercepts_hidden
      array([[  1.,   1.,   1.],
             [  0.,   0.,  nan]])

      If possible, type conversions are performed:

      >>> ann.intercepts_hidden = '2'
      >>> ann.intercepts_hidden
      array([[ 2.,  2.,  2.],
             [ 2.,  2.,  2.]])

      One can assign whole matrices directly:

      >>> import numpy
      >>> ann.intercepts_hidden = [1.0, 3.0, 2.0]
      >>> ann.intercepts_hidden
      array([[ 1.,  3.,  2.],
             [ 1.,  3.,  2.]])

      One can also delete the values contained in the array:

      >>> del ann.intercepts_hidden
      >>> ann.intercepts_hidden
      array([[  0.,   0.,   0.],
             [  0.,   0.,  nan]])

      Errors like wrong shapes (or unconvertible inputs) result in
      error messages:

      >>> ann.intercepts_hidden = [1.0, 3.0]
      Traceback (most recent call last):
      ...
      ValueError: While trying to set the neuron related intercepts of the artificial neural network `ann` of element `?`, the following error occured: could not broadcast input array from shape (2) into shape (2,3)

      The number of input intercepts is available as a property:

      >>> ann.nmb_intercepts_hidden
      5

   shape_intercepts_hidden

      Shape if the array containing the intercepts of neurons of the
      hidden layers.

   nmb_intercepts_hidden

      Number of input intercepts.

   intercepts_output

      Intercepts of all output nodes.

      All intercepts are handled in a 1-dimensional array:

      >>> from hydpy import ANN
      >>> ann = ANN()
      >>> ann(nmb_outputs=3)
      >>> ann.intercepts_output
      array([ 0.,  0.,  0.])

      It is allowed to set values via slicing:

      >>> ann.intercepts_output[1:] = 1.
      >>> ann.intercepts_output
      array([ 0.,  1.,  1.])

      If possible, type conversions are performed:

      >>> ann.intercepts_output = '2'
      >>> ann.intercepts_output
      array([ 2.,  2.,  2.])

      One can assign whole matrices directly:

      >>> import numpy
      >>> ann.intercepts_output = [1.0, 3.0, 2.0]
      >>> ann.intercepts_output
      array([ 1.,  3.,  2.])

      One can also delete the values contained in the array:

      >>> del ann.intercepts_output
      >>> ann.intercepts_output
      array([ 0.,  0.,  0.])

      Errors like wrong shapes (or unconvertible inputs) result in
      error messages:

      >>> ann.intercepts_output = [1.0, 3.0]
      Traceback (most recent call last):
      ...
      ValueError: While trying to set the output node related intercepts of the artificial neural network `ann` of element `?`, the following error occured: could not broadcast input array from shape (2) into shape (3)

   shape_intercepts_output

      Shape if the array containing the intercepts of neurons of the
      hidden layers.

      >>> from hydpy import dummies
      >>> dummies.ann.shape_intercepts_output
      (1,)

   nmb_intercepts_output

      Number of output intercepts.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_intercepts_output
      1

   inputs

      Values of the input nodes.

      All input values are handled in a 1-dimensional array:

      >>> from hydpy import ANN
      >>> ann = ANN()
      >>> ann(nmb_inputs=3)
      >>> ann.inputs
      array([ 0.,  0.,  0.])

      It is allowed to set values via slicing:

      >>> ann.inputs[1:] = 1.
      >>> ann.inputs
      array([ 0.,  1.,  1.])

      If possible, type conversions are performed:

      >>> ann.inputs = '2'
      >>> ann.inputs
      array([ 2.,  2.,  2.])

      One can assign whole matrices directly:

      >>> import numpy
      >>> ann.inputs = [1.0, 3.0, 2.0]
      >>> ann.inputs
      array([ 1.,  3.,  2.])

      One can also delete the values contained in the array:

      >>> del ann.inputs
      >>> ann.inputs
      array([ 0.,  0.,  0.])

      Errors like wrong shapes (or unconvertible inputs) result in
      error messages:

      >>> ann.inputs = [1.0, 3.0]
      Traceback (most recent call last):
      ...
      ValueError: While trying to set the inputs of the artificial neural network `ann` of element `?`, the following error occured: could not broadcast input array from shape (2) into shape (3)

   outputs

      Values of the output nodes.

      All output values are handled in a 1-dimensional array:

      >>> from hydpy import ANN
      >>> ann = ANN()
      >>> ann(nmb_outputs=3)
      >>> ann.outputs
      array([ 0.,  0.,  0.])

      It is not allowed to change output values manually:

      >>> ann.outputs = 1.0
      Traceback (most recent call last):
      ...
      AttributeError: Attribute `outputs` of object `ann` cannot be used this way.

   neurons

      The activation of the neurons of the hidden layers.

      >>> from hydpy import dummies
      >>> dummies.ann.neurons
      array([[ 1.,  1.],
             [ 0.,  0.]])

   process_actual_input()

      Calculates the network output values based on the input values
      defined previously.

      For more information see the documentation on class

      ANN

      .

   nmb_weights

      Number of all input, inner, and output weights.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_weights
      7

   nmb_intercepts

      Number of all inner and output intercepts.

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_intercepts
      4

   nmb_parameters

      Sum of

      nmb_weights

       and

      nmb_intercepts

      .

      >>> from hydpy import dummies
      >>> dummies.ann.nmb_parameters
      11

   verify()

      Raise a

      RuntimeError

       if the network's shape is not defined completely.

      >>> from hydpy import dummies
      >>> dummies.ann.verify()

      >>> from hydpy import ANN
      >>> ANN().verify()
      Traceback (most recent call last):
      ...
      RuntimeError: The shape of the the artificial neural network parameter `ann` of element `?` has not been defined so far.

   assignrepr(prefix)

      Return a string representation of the actual

      ANN

       object that is prefixed with the given string.

   plot(xmin, xmax, idx_input=0, idx_output=0, points=100, **kwargs)

      Plot the relationship between a certain input (*idx_input*) and
      a certain output (*idx_output*) variable described by the actual

      ANN

       object.

      Define the lower and the upper bound of the x axis via arguments
      *xmin* and *xmax*.  The number of plotting points can be
      modified by argument *points*.  Additional *matplotlib* plotting
      arguments can be passed as keyword arguments.

hydpy.auxs.anntools.ann(**kwargs)

   Return a new stand alone

   ANN

    object with the given parameter values.

   The purpose of this function is to allow for string representations
   of parameters containing multiple

   ANN

    instances.

   When passing no arguments, the default values of class

   ANN

    will be applied:

   >>> from hydpy import ANN
   >>> ann1 = ann()
   >>> ann1
   ann(nmb_inputs=1,
       nmb_neurons=(1,),
       nmb_outputs=1,
       weights_input=[[0.0]],
       weights_output=[[0.0]],
       intercepts_hidden=[[0.0]],
       intercepts_output=[0.0])

   Of course, all parameter values can be changed:

   >>> ann2 = ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...            weights_input=4.0, weights_output=3.0,
   ...            intercepts_hidden=-16.0, intercepts_output=-1.0)
   >>> ann2
   ann(nmb_inputs=1,
       nmb_neurons=(1,),
       nmb_outputs=1,
       weights_input=[[4.0]],
       weights_output=[[3.0]],
       intercepts_hidden=[[-16.0]],
       intercepts_output=[-1.0])

   The following line is just thought to make clear, that two
   independent

   ANN

    objects have been initialized (instead of changing the values of
   an existing

   ANN

    object vai its *call* method):

   >>> ann1 is ann2
   False

class hydpy.auxs.anntools.SeasonalANN

   Bases:

   object

   Handles relationships described by artificial neural networks that
   vary within an anual cycle.

   Class

   SeasonalANN

    is an alternative implementation of class

   SeasonalParameter

    specifically designed for handling multiple

   ANN

    objects that are valid for different times of the year, described
   by

   TOY

    objects.  The total output of a

   SeasonalANN

    object is a weighted mean of the output of one or two "normal"
   neural networks.

   ratios

    used for weighting depend on the actual time of the year.

   To explain this in more detail, let us define a

   SeasonalANN

    object first, that contains three "normal" networks for January,
   1, March, 1, and July, 1, respectively (note that this example is
   similar to the example used to describe class

   SeasonalParameter

   ):

   >>> from hydpy import SeasonalANN, ann
   >>> seasonalann = SeasonalANN()
   >>> seasonalann.simulationstep = '1d'
   >>> seasonalann(
   ...     _1_1_12=ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...                 weights_input=0.0, weights_output=0.0,
   ...                 intercepts_hidden=0.0, intercepts_output=1.0),
   ...     _7_1_12=ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...                 weights_input=4.0, weights_output=3.0,
   ...                 intercepts_hidden=-16.0, intercepts_output=-1.0),
   ...     _3_1_12=ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...                 weights_input=0.0, weights_output=0.0,
   ...                 intercepts_hidden=0.0, intercepts_output=-1.0))

   The confused time order in the initialization call above does not
   pose a problem, as

   SeasonalANN

    performs time sorting internally:

   >>> seasonalann
   seasonalann(toy_1_1_12_0_0=ann(nmb_inputs=1,
                                  nmb_neurons=(1,),
                                  nmb_outputs=1,
                                  weights_input=[[0.0]],
                                  weights_output=[[0.0]],
                                  intercepts_hidden=[[0.0]],
                                  intercepts_output=[1.0]),
               toy_3_1_12_0_0=ann(nmb_inputs=1,
                                  nmb_neurons=(1,),
                                  nmb_outputs=1,
                                  weights_input=[[0.0]],
                                  weights_output=[[0.0]],
                                  intercepts_hidden=[[0.0]],
                                  intercepts_output=[-1.0]),
               toy_7_1_12_0_0=ann(nmb_inputs=1,
                                  nmb_neurons=(1,),
                                  nmb_outputs=1,
                                  weights_input=[[4.0]],
                                  weights_output=[[3.0]],
                                  intercepts_hidden=[[-16.0]],
                                  intercepts_output=[-1.0]))

   The property

   shape

    does reflect the number of required weighting ratios for each time
   of year (in this example: 366 days per year) and each neural
   network (in this example: three):

   >>> seasonalann.shape
   (366, 3)

   For safety reasons,

   shape

    should normally not be changed manually:

   >>> seasonalann.shape = (366, 4)
   Traceback (most recent call last):
   ...
   AttributeError: can't set attribute

   The following interactive shows how the

   ratios

    used for weighting are calculated:

   For example, on July, 1 (which is the 183th day of a leap year),
   only the output of the third network is relevant:

   >>> from hydpy import print_values
   >>> print_values(seasonalann.ratios[182])
   0.0, 0.0, 1.0

   On Juni, 30, and July, 2, also the second and the first neural
   network are relevant, respectively:

   >>> print_values(seasonalann.ratios[181])
   0.0, 0.008197, 0.991803
   >>> print_values(seasonalann.ratios[183])
   0.005435, 0.0, 0.994565

   Inserting data, processing this data, and fetching the output works
   as explained for class

   ANN

   , except that the index of the actual time of year needs to be
   passed as the single argument of

   process_actual_input()

   .  Passing the index value *182* activates the third network only,
   which is configured exactly as the one exemplifying class

   ANN

   :

   >>> from hydpy import round_
   >>> for input_ in range(9):
   ...     seasonalann.inputs[0] = input_
   ...     seasonalann.process_actual_input(182)
   ...     round_([input_, seasonalann.outputs[0]])
   0, -1.0
   1, -0.999982
   2, -0.998994
   3, -0.946041
   4, 0.5
   5, 1.946041
   6, 1.998994
   7, 1.999982
   8, 2.0

   To see that the final output values are actually the weighted mean
   of the output values of the single neural networks, we repeat the
   above example for January, 13, where the first and the second
   neural network have ratios of 0.8 and 0.2 respectively:

   >>> print_values(seasonalann.ratios[12])
   0.8, 0.2, 0.0

   For both networks all parameters except the output intercepts are
   zero.  Hence, the calculated output is independent of the given
   input. The output of the first network (1.0) dominates the output
   of the second network (-1.0):

   >>> from hydpy import round_
   >>> for input_ in range(9):
   ...     seasonalann.inputs[0] = input_
   ...     seasonalann.process_actual_input(12)
   ...     round_([input_, seasonalann.outputs[0]])
   0, 0.6
   1, 0.6
   2, 0.6
   3, 0.6
   4, 0.6
   5, 0.6
   6, 0.6
   7, 0.6
   8, 0.6

   It is of great importance that all contained neural networks are
   consistent.  Hence some tests are performed:

   >>> seasonalann = SeasonalANN()
   >>> seasonalann.process_actual_input(0)
   Traceback (most recent call last):
   ...
   RuntimeError: The seasonal neural network collection `seasonalann` of element `?` has not been properly prepared so far.

   >>> seasonalann(1)
   Traceback (most recent call last):
   ...
   TypeError: Type `int` is not (a subclass of) type `ANN`.

   >>> seasonalann(
   ...     _13_1_12=ann(nmb_inputs=2, nmb_neurons=(1,), nmb_outputs=1,
   ...                  weights_input=0.0, weights_output=0.0,
   ...                  intercepts_hidden=0.0, intercepts_output=1.0))
   Traceback (most recent call last):
   ...
   ValueError: While trying to add a season specific neural network to parameter `seasonalann` of element `?`, the following error occured: While trying to retrieve the month for TOY (time of year) object based on the string `_13_1_12`, the following error occured: The value of property `month` of TOY (time of year) objects must lie within the range `(1, 12)`, but the given value is `13`.

   >>> seasonalann(
   ...     ann(nmb_inputs=2, nmb_neurons=(1,), nmb_outputs=1,
   ...         weights_input=0.0, weights_output=0.0,
   ...         intercepts_hidden=0.0, intercepts_output=1.0))
   >>> seasonalann
   seasonalann(ann(nmb_inputs=2,
                   nmb_neurons=(1,),
                   nmb_outputs=1,
                   weights_input=[[0.0],
                                  [0.0]],
                   weights_output=[[0.0]],
                   intercepts_hidden=[[0.0]],
                   intercepts_output=[1.0]))

   >>> seasonalann(
   ...     ann(nmb_inputs=2, nmb_neurons=(1,), nmb_outputs=1,
   ...         weights_input=0.0, weights_output=0.0,
   ...         intercepts_hidden=0.0, intercepts_output=1.0),
   ...     _7_1_12=ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...                 weights_input=4.0, weights_output=3.0,
   ...                 intercepts_hidden=-16.0, intercepts_output=-1.0),
   ...     _3_1_12=ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...                 weights_input=0.0, weights_output=0.0,
   ...                 intercepts_hidden=0.0, intercepts_output=-1.0))
   Traceback (most recent call last):
   ...
   ValueError: Type `SeasonalANN` accepts either a single positional argument or an arbitrary number of keyword arguments, but for the corresponding parameter of element `?` 1 positional and 2 keyword arguments have been given.

   >>> seasonalann(
   ...     _1_1_12=ann(nmb_inputs=2, nmb_neurons=(1,), nmb_outputs=1,
   ...                 weights_input=0.0, weights_output=0.0,
   ...                 intercepts_hidden=0.0, intercepts_output=1.0),
   ...     _7_1_12=ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...                 weights_input=4.0, weights_output=3.0,
   ...                 intercepts_hidden=-16.0, intercepts_output=-1.0),
   ...     _3_1_12=ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...                 weights_input=0.0, weights_output=0.0,
   ...                 intercepts_hidden=0.0, intercepts_output=-1.0))
   Traceback (most recent call last):
   ...
   RuntimeError: The number of input and output values of all neural networks contained by a seasonal neural network collection must be identical and be known by the containing object.  But the seasonal neural network collection `seasonalann` of element `?` assumes `2` input and `1` output values, while the network corresponding to the time of year `toy_3_1_12_0_0` requires `1` input and `1` output values.

   Whenever a test fails, all networks are removed for safety:

   >>> seasonalann
   seasonalann()

   Alternatively, neural networks can be added individually via
   attribute access:

   >>> jan = ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
   ...           weights_input=0.0, weights_output=0.0,
   ...           intercepts_hidden=0.0, intercepts_output=1.0)
   >>> seasonalann.toy_1_1_12 = jan

   Setting an attribute updates everything, e.g.:

   >>> round_(seasonalann.ratios[0])
   1.0

   The mentioned safety checks do also apply when adding networks via
   attribute access, e.g.:

   >>> seasonalann.toy_7_1_12 = ann(nmb_inputs=2,
   ...                              nmb_neurons=(1,),
   ...                              nmb_outputs=1,
   ...                              weights_input=0.0,
   ...                              weights_output=0.0,
   ...                              intercepts_hidden=0.0,
   ...                              intercepts_output=1.0)
   Traceback (most recent call last):
   ...
   RuntimeError: While trying to assign a new neural network to the seasonal neural network collection `seasonalann` of element `?` based on name `toy_7_1_12`, the following error occured: The number of input and output values of all neural networks contained by a seasonal neural network collection must be identical and be known by the containing object.  But the seasonal neural network collection `seasonalann` of element `?` assumes `1` input and `1` output values, while the network corresponding to the time of year `toy_7_1_12_0_0` requires `2` input and `1` output values.

   Besides setting new networks, getting and deleting them are also
   suppported:

   >>> seasonalann.toy_1_1_12 = jan
   >>> seasonalann.toy_1_1_12
   ann(nmb_inputs=1,
       nmb_neurons=(1,),
       nmb_outputs=1,
       weights_input=[[0.0]],
       weights_output=[[0.0]],
       intercepts_hidden=[[0.0]],
       intercepts_output=[1.0])
   >>> del seasonalann.toy_1_1_12

   These error messages related to attribute access are provided:

   >>> seasonalann.toy_1_1_12
   Traceback (most recent call last):
   ...
   AttributeError: While trying to look up for a neural network handled by the seasonal neural network collection `seasonalann` of element `?` based on name `toy_1_1_12`, the following error occured: No neural network is registered under a TOY object named `toy_1_1_12_0_0`.

   >>> del seasonalann.toy_1_1_12
   Traceback (most recent call last):
   ...
   AttributeError: While trying to remove a new neural network from the seasonal neural network collection `seasonalann` of element `?` based on name `toy_1_1_12`, the following error occured: No neural network is registered under a TOY object named `toy_1_1_12_0_0`.

   >>> seasonalann.toy_1_1_12 = 1
   Traceback (most recent call last):
   ...
   TypeError: While trying to assign a new neural network to the seasonal neural network collection `seasonalann` of element `?` based on name `toy_1_1_12`, the following error occured: Value `1` of type `int` has been given, but a value of type `ANN` is required.

   Setting and deleting "normal" attributes is supported:

   >>> seasonalann.temp = 999
   >>> seasonalann.temp
   999
   >>> del seasonalann.temp
   >>> seasonalann.temp
   Traceback (most recent call last):
   ...
   AttributeError: 'SeasonalANN' object has no attribute 'temp'

   NDIM = 0

   TYPE = 'annutils.SeasonalANN'

   TIME = None

   SPAN = (None, None)

   parameterstep = Period()

   simulationstep = Period()

   connect(subpars)

      Connect the actual

      SeasonalANN

       object with the given

      SubParameters

       object.

   name

      Name of the class of the given instance in lower case letters.

      This function is thought to be implemented as a property.
      Otherwise it would violate the principle not to access or
      manipulate private attributes ("_name"):

      >>> from hydpy.core.objecttools import name
      >>> class Test(object):
      ...     name = property(name)
      >>> test1 = Test()
      >>> test1.name
      'test'
      >>> test1._name
      'test'

      The private attribute is added for performance reasons only.
      Note that it is a class attribute:

      >>> test2 = Test()
      >>> test2._name
      'test'

   refresh()

      Prepare the actual

      SeasonalANN

       object for calculations.

      Dispite all automated refreshings explained in the general
      documentation on class

      SeasonalANN

      , it is still possible to destroy the inner consistency of a

      SeasonalANN

       instance, as it stores its

      ANN

       objects by reference.  This is shown by the following example:

      >>> from hydpy import SeasonalANN, ann
      >>> seasonalann = SeasonalANN()
      >>> seasonalann.simulationstep = '1d'
      >>> jan = ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
      ...           weights_input=0.0, weights_output=0.0,
      ...           intercepts_hidden=0.0, intercepts_output=1.0)
      >>> seasonalann(_1_1_12=jan)
      >>> jan.nmb_inputs, jan.nmb_outputs = 2, 3
      >>> jan.nmb_inputs, jan.nmb_outputs
      (2, 3)
      >>> seasonalann.nmb_inputs, seasonalann.nmb_outputs
      (1, 1)

      Due to the C level implementation of the mathematical core of
      both

      ANN

       and

      SeasonalANN

       in module "annutils", such an inconsistency might result in a
      program crash without any informative error message.  Whenever
      you are afraid some inconsistency might have crept in, and you
      want to repair it, call method

      refresh()

       explicitly:

      >>> seasonalann.refresh()
      >>> jan.nmb_inputs, jan.nmb_outputs
      (2, 3)
      >>> seasonalann.nmb_inputs, seasonalann.nmb_outputs
      (2, 3)

   verify()

      Raise a

      RuntimeError

       and removes all handled neural networks, if the they are
      defined inconsistently.

      Dispite all automated safety checks explained in the general
      documentation on class

      SeasonalANN

      , it is still possible to destroy the inner consistency of a

      SeasonalANN

       instance, as it stores its

      ANN

       objects by reference.  This is shown by the following example:

      >>> from hydpy import SeasonalANN, ann
      >>> seasonalann = SeasonalANN()
      >>> seasonalann.simulationstep = '1d'
      >>> jan = ann(nmb_inputs=1, nmb_neurons=(1,), nmb_outputs=1,
      ...           weights_input=0.0, weights_output=0.0,
      ...           intercepts_hidden=0.0, intercepts_output=1.0)
      >>> seasonalann(_1_1_12=jan)
      >>> jan.nmb_inputs, jan.nmb_outputs = 2, 3
      >>> jan.nmb_inputs, jan.nmb_outputs
      (2, 3)
      >>> seasonalann.nmb_inputs, seasonalann.nmb_outputs
      (1, 1)

      Due to the C level implementation of the mathematical core of
      both

      ANN

       and

      SeasonalANN

       in module "annutils", such an inconsistency might result in a
      program crash without any informative error message.  Whenever
      you are afraid some inconsistency might have crept in, and you
      want to find out if this is actually the case, call method

      verify()

       explicitly:

      >>> seasonalann.verify()
      Traceback (most recent call last):
      ...
      RuntimeError: The number of input and output values of all neural networks contained by a seasonal neural network collection must be identical and be known by the containing object.  But the seasonal neural network collection `seasonalann` of element `?` assumes `1` input and `1` output values, while the network corresponding to the time of year `toy_1_1_12_0_0` requires `2` input and `3` output values.

      >>> seasonalann
      seasonalann()

      >>> seasonalann.verify()
      Traceback (most recent call last):
      ...
      RuntimeError: Seasonal artificial neural network collections need to handle at least one "normal" single neural network, but for the seasonal neural network `seasonalann` of element `?` none has been defined so far.

   shape

      The shape of array

      ratios

      .

   toys

      A sorted

      tuple

       of all contained

      TOY

       objects.

   anns

      A sorted

      tuple

       of all contained

      ANN

       objects.

   ratios

      Ratios for weighting the single neural network outputs.

   nmb_inputs

      Number of input values of all neural networks.

   inputs

      General input data for all neural networks.

   nmb_outputs

      Number of output values of all neural networks.

   outputs

      Weighted output of the individual neural networks.

   process_actual_input(idx_toy)

      Calculate the network output values based on the input values
      defined previously for the given index referencing the actual
      time of year.

   plot(xmin, xmax, idx_input=0, idx_output=0, points=100, **kwargs)

      Call method

      plot()

       of all

      ANN

       objects handled bythe actual

      SeasonalANN

       object.
